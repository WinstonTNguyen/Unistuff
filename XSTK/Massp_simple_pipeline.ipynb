{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![logo price](./imgs/massp_logo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructors\n",
    "* Vương Phúc Thành\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Bài toán Giới thiệu về pipeline cho một bài toán Machine learning\n",
    "![home price](./imgs/wine-dataset.jpeg)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "###  Mô tả :\n",
    "Bài toán đưa ra yêu cầu chúng ta phân loại và chấm điểm chất lượng rượu dựa vào các chỉ số thành phần của rượu. \n",
    "- Đầu vào: một bảng thông tin tổng quan các chỉ số của rượu\n",
    "- Đầu ra: chất lượng rượu, đánh số từ 0 đến 10\n",
    "\n",
    "Mục tiêu: Xây dựng mô hình học máy dựa trên tập training (bao gồm đầu vào và đầu ra) để dự đoán chất lượng của rượu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction of Wine quality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outline\n",
    "\n",
    "- <a href='#1'>1. Problem defining</a>\n",
    "\n",
    "- <a href='#2'>2. Khai phá dữ liệu </a>  \n",
    "\n",
    "- <a href='#3'>3. Data analyzing - Phân tích dữ liệu </a>\n",
    "    - <a id='#3.1'>3.1. Tổng quan trường target </a>\n",
    "    - <a id='#3.2'>3.2. Metric đánh giá </a> \n",
    "    - <a id='#3.3'>3.3. Khai phá dữ liệu </a> \n",
    "- <a href='#4'>4. Feature engineering </a>\n",
    "    - <a id='#4-1'>4.1. Log transform </a>\n",
    "    - <a id='#4-2'>4.2. Xử lí imbalanced data</a> \n",
    "    - <a id='#4-3'>4.3. Xử lí null data</a> \n",
    "- <a href='#5'>5. Modeling and evaluating </a>\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='1'>1. Problem defining"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Bài toán đưa ra đầu vào các chỉ số của 1 cốc rượu, chúng ta cần dựa vào các chỉ số đó để đánh giá rượu có phải loại ngon hay không:\n",
    "Các chỉ số của rượu là:\n",
    "\n",
    " 1 - fixed acidity          : nồng độ cồn\n",
    " 2 - volatile acidity       : nồng độ cồn bay hơi ~> càng cao thì rượu càng có vị chua \n",
    " 3 - citric acid            : nồng độ axit citric ~> tạo vị thanh mát cho rượu\n",
    " 4 - residual sugar         : độ ngọt ~> lượng đường trong rượu\n",
    " 5 - chlorides              : lượng muối trong rượu\n",
    " 6 - free sulfur dioxide    : nồng độ SO2 ở dạng free form\n",
    " 7 - total sulfur dioxide   : tổng nồng độ SO2\n",
    " 8 - density                : độ đậm đặc của lượng cồn, đường và nước\n",
    " 9 - pH                     : độ pH\n",
    " 10 - sulphates             : chất phụ gia chống vi khuẩn\n",
    " 11 - alcohol               : nồng độ cồn\n",
    " Output variable (based on sensory data):\n",
    " 12 - quality (score between 0 and 10) ~> Label, chất lượng rượu\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Chúng ta sẽ sử dụng model classification để phân loại rượu vào thang điểm từ 0 - 10. Đối với bài classification sẽ là 10 classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='2'>2. Data collecting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Đối với bài toán này ta đã có sẵn 1 tập data trong file csv, có thể load và sử dụng ngay, không cần qua các bước thu thập và load vào database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-1-7846b688b1b0>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[1;31m## import các thư viện cần thiết\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mos\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 3\u001B[1;33m \u001B[1;32mimport\u001B[0m \u001B[0mnumpy\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      4\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mpandas\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0mpd\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mmatplotlib\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpyplot\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0mplt\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'numpy'"
     ]
    }
   ],
   "source": [
    "## import các thư viện cần thiết\n",
    "import os  \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder, label_binarize, StandardScaler, PolynomialFeatures, MinMaxScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix, mean_squared_error\n",
    "\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"data/winequalityN.csv\")\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='3'> 3. Data analyzing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Một vài thông tin tổng quan tập dữ liệu:\n",
    "print(\"Kích thước tập dữ liệu: {}\".format(df.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='3.1'> 3.1 Tổng quan trường target (quality)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['quality'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## phân bố cột dữ liệu quality\n",
    "sns.countplot(df['quality'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nhận xét: số lượng rượu với quality 5 và 6 lớn hơn nhiều lần so với các class khác. Nếu ta giữ nguyên phân bố như vậy, có thể sẽ có vấn đề khi dự đoán chất lượng của rượu, do dữ liệu bị imbalanced. \n",
    "=> Chúng ta có thể xử lí bằng cách giảm số lượng class 5 và 6 xuống (undersampling) hoặc tăng số lượng các class khác lên (oversampling) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='3.2'> 3.2 Metric đánh giá:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Đối với 1 bài toán Ordinal Regression, chúng ta có thể sử dùng công thức Mean squared error (Ước lượng trung bình bình phương sai số):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(url='./imgs/MSE.jpg', width=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Đối với 1 bài toán classification, ở đây ta chia label bài toán ra làm 10 classes khác nhau, có thể dùng confusion matrix và f1-score để đánh giá:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(url='./imgs/cm_2.png', width=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(url='./imgs/F1-Score.png', width=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Trong đó\n",
    "Image(url='./imgs/precision_recall.jpeg', width=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Đặt câu hỏi và giải đáp về các metrics !?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chúng ta sẽ nhìn qua bộ dữ liệu, xử lí dữ liệu nhiễu và dữ liệu bị thiếu, kiểm tra type của các cột và điều chỉnh lại cho chuẩn\n",
    "để sử dụng cho việc phân tích."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Số lượng missing values của từng cột \n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Có tất cả 13 cột giá trị và 6497 dòng, 1 số cột có giá trị bị thiếu (null value). Định dạng dữ liệu chủ yếu là float64 ~> có thể sử dụng mà k cần biến đổi nhiều, cột type va quality có thể biến đổi về float."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='3.3'>3.3 Data exploratory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Có 12 trường tất cả, vậy việc phân tích dữ liệu sẽ không quá phức tạp, chúng ta sẽ nhìn qua từng trường một. Đầu tiên, nhìn qua phần summary của dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Đầu tiên cần nhận thấy rằng các trường đang phân bố ở các scale khác nhau, vậy sau này ta sẽ cần rescale lại data.\n",
    "Có 1 trường object duy nhất, ta sẽ kiểm tra xem liệu màu của rượu (đỏ hoặc trắng) có ảnh hưởng nhiều đến quality hay ko?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x=\"type\",y=\"quality\",data=df, palette=\"dark\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=> nhận thấy rằng type của rượu k ảnh hưởng gì nhiều đến quality của nó, ta có thể drop cột này."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cùng nhìn qua phân bố của các class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (18, 4))\n",
    "title = fig.suptitle(\"Wine Type Vs Quality\", fontsize=14)\n",
    "fig.subplots_adjust(top=0.85, wspace=0.3)\n",
    "\n",
    "ax1 = fig.add_subplot(1,4, 1)\n",
    "ax1.set_title(\"Red Wine\")\n",
    "ax1.set_xlabel(\"Quality\")\n",
    "ax1.set_ylabel(\"Frequency\") \n",
    "rw_q = df.quality[df.type == 'red'].value_counts()\n",
    "rw_q = (list(rw_q.index), list(rw_q.values))\n",
    "ax1.set_ylim([0, 2500])\n",
    "ax1.tick_params(axis='both', which='major', labelsize=8.5)\n",
    "bar1 = ax1.bar(rw_q[0], rw_q[1], color='red', edgecolor='black', linewidth=1)\n",
    "\n",
    "\n",
    "ax2 = fig.add_subplot(1,4, 2)\n",
    "ax2.set_title(\"White Wine\")\n",
    "ax2.set_xlabel(\"Quality\")\n",
    "ax2.set_ylabel(\"Frequency\") \n",
    "ww_q = df.quality[df.type == 'white'].value_counts()\n",
    "ww_q = (list(ww_q.index), list(ww_q.values))\n",
    "ax2.set_ylim([0, 2500])\n",
    "ax2.tick_params(axis='both', which='major', labelsize=8.5)\n",
    "bar2 = ax2.bar(ww_q[0], ww_q[1], color='white', edgecolor='black', linewidth=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Kiểm tra outlier của data\n",
    "# tạo box plot\n",
    "fig, ax = plt.subplots(ncols=6, nrows=2, figsize=(20,10))\n",
    "index = 0\n",
    "ax = ax.flatten()\n",
    "\n",
    "for col, value in df.items():\n",
    "    if col != 'type':\n",
    "        sns.boxplot(y=col, data=df, color='r', ax=ax[index])\n",
    "        index += 1\n",
    "plt.tight_layout(pad=0.5, w_pad=0.7, h_pad=5.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "fig, ax1 = plt.subplots(3,4, figsize=(24,30))\n",
    "k = 0\n",
    "columns = list(df.columns)\n",
    "for i in range(3):\n",
    "    for j in range(4):\n",
    "            sns.boxplot(df['quality'], df[columns[k]], ax = ax1[i][j], palette='pastel')\n",
    "            k += 1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nhận xét: hầu hết các trường đều có outlier! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sử dụng heat map để tìm correlation\n",
    "plt.figure(figsize=(15,8))\n",
    "sns.heatmap(df.corr(), annot=True, linewidths=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Ma trận heatmap là cách tốt nhất để thấy được mối quan hệ giữa các trường số với nhau.\n",
    "- Mỗi tọa độ của ma trận thể hiện mối tương quan giữa 2 cột.\n",
    "- Correlation càng gần 1, thì 2 trường càng có sự giống nhau.\n",
    "- Nếu các trường (khác target) có correlation cao, có thể xem xét bỏ đi một cột.\n",
    "- Nếu một trường có correlation cao với target, thì trường đó được xem xét như một feature quan trọng."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 vài insights từ bảng trên:\n",
    "- tỉ lệ alcohol trong rượu đồng biến với quality => alcohol nhiều thì rượu chất lượng càng cao\n",
    "- alcohol và ph có mối liên hệ yếu, không đáng kể\n",
    "- Citric acid và density có mối tương quan khá mạnh với fixed acidity.\n",
    "- pH nghịch biến với density, fixed acidity, citric acid, and sulfates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,15))\n",
    "df.corr().quality.apply(lambda x: abs(x)).sort_values(ascending=False).iloc[1:11][::-1].plot(kind='barh',color='pink') \n",
    "# calculating the top 10 highest correlated features\n",
    "# with respect to the target variable i.e. \"quality\"\n",
    "plt.title(\"Top 10 highly correlated features\", size=20, pad=26)\n",
    "plt.xlabel(\"Correlation coefficient\")\n",
    "plt.ylabel(\"Features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Đánh giá alcohol vs quality\n",
    "sns.boxplot(x='quality', y='alcohol', data = df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Các chấm đen thể hiện đó là outlier, chủ yếu ở những chai rượu có quality = 5, ta có thể bỏ qua outlier bằng cách thêm argument showoutliers=False  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x='quality', y='alcohol', data = df, showfliers=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=> Nồng độ alcohol cao => chất lượng rượu càng cao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xem phân bố của cột alchohol\n",
    "sns.distplot(df['alcohol'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ta có thể thấy rằng phần bố của alcohol skew với chất lượng của rượu. Kiểm tra mức độ skew của phân bố sử dụng scipy.stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import skew\n",
    "skew(df['alcohol'])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "=> positive skew => mean > median > mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Vẽ phân bố của tất cả các field trong tập dữ liệu\n",
    "plt.figure(figsize=(15,8))\n",
    "fig, ax = plt.subplots(ncols=6, nrows=2, figsize=(20,10))\n",
    "index = 0\n",
    "ax = ax.flatten()\n",
    "\n",
    "for col, value in df.items():\n",
    "    if col != 'type':\n",
    "        sns.distplot(value, color='r', ax=ax[index])\n",
    "        index += 1\n",
    "plt.tight_layout(pad=0.5, w_pad=0.7, h_pad=5.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Các hình trên biểu diễn phân bố của từng cột dữ liệu\n",
    "- Có các features có phân bố chuẩn, còn lại chủ yếu là right skew distribution. Range của từng feature cũng ko quá rộng\n",
    "- Ta cần transform các skewed feature, sử dụng log transfrom sẽ giải quyết được vấn đề!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='4'> 4. Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 vài step chúng ta cần xử lí dữ liệu sau khi đã phân tích qua các features:\n",
    "- Fill null values\n",
    "- log transform\n",
    "- rescale data\n",
    "- xử lí imbalanced data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='4.1'> 4.1 Log transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ví dụ về output của log_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_transform(col):\n",
    "    return np.log(col)\n",
    "\n",
    "fixed_acidity_transformed = df[['fixed acidity']].apply(log_transform, axis=1)\n",
    "chlorides_transformed = df[['chlorides']].apply(log_transform, axis=1)\n",
    "free_sulfur_dioxide_transformed = df[['free sulfur dioxide']].apply(log_transform, axis=1)\n",
    "sulphates_transformed = df[['sulphates']].apply(log_transform, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Vẽ phân bố của tất cả các field trong tập dữ liệu\n",
    "sns.distplot(fixed_acidity_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(chlorides_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(free_sulfur_dioxide_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(sulphates_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.corr()['quality'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- correlation giữa các feature với target không cao lắm, nhưng có thể thấy các feature quan trọng là alcohol, density, volatile acidity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hàm xử lí log_transform\n",
    "def log_transform(col):\n",
    "    return np.log(col[0])\n",
    "\n",
    "df['fixed acidity']= df[['fixed acidity']].apply(log_transform, axis=1)\n",
    "df['chlorides'] = df[['chlorides']].apply(log_transform, axis=1)\n",
    "df['free sulfur dioxide'] = df[['free sulfur dioxide']].apply(log_transform, axis=1)\n",
    "df['sulphates'] = df[['sulphates']].apply(log_transform, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='4.2'> 4.2 Xử lí imbalanced data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![home price](./imgs/smote.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The simplest implementation of over-sampling is to duplicate random records from the minority class, which can cause overfishing.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In under-sampling, the simplest technique involves removing random records from the majority class, which can cause loss of information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3 = df[df.quality==3]     # MINORITY          \n",
    "df_4 = df[df.quality==4]     # MINORITY          \n",
    "df_5 = df[df.quality==5]     # MAJORITY\n",
    "df_6 = df[df.quality==6]     # MAJORITY\n",
    "df_7 = df[df.quality==7]     # MINORITY\n",
    "df_8 = df[df.quality==8]     # MINORITY\n",
    "df_9 = df[df.quality==9]     # MINORITY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Oversample MINORITY Class to make balance data :\n",
    "from sklearn.utils import resample\n",
    "\n",
    "df_3_upsampled = resample(df_3, replace=True, n_samples=2000) \n",
    "df_4_upsampled = resample(df_4, replace=True, n_samples=2000) \n",
    "df_7_upsampled = resample(df_7, replace=True, n_samples=2000) \n",
    "df_8_upsampled = resample(df_8, replace=True, n_samples=2000) \n",
    "df_9_upsampled = resample(df_9, replace=True, n_samples=2000) \n",
    "# Decreases the rows of Majority one's to make balance data :\n",
    "df_5_downsampled = df[df.quality==5].sample(n=2000).reset_index(drop=True)\n",
    "df_6_downsampled = df[df.quality==6].sample(n=2000).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine downsampled majority class with upsampled minority class\n",
    "Balanced_df = pd.concat([df_3_upsampled, df_4_upsampled, df_7_upsampled, \n",
    "                         df_8_upsampled, df_5_downsampled, df_6_downsampled, df_9_upsampled ]).reset_index(drop=True)\n",
    "\n",
    "\n",
    "# Display new class counts\n",
    "Balanced_df.quality.value_counts()           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "sns.countplot(x='quality', data=Balanced_df, order=[3, 4, 5, 6, 7, 8, 9], palette='pastel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (12,6))\n",
    "sns.barplot(x='quality', y = 'alcohol', data = df, palette = 'coolwarm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,15))\n",
    "Balanced_df.corr().quality.apply(lambda x: abs(x)).sort_values(ascending=False).iloc[1:11][::-1].plot(kind='barh',color='pink') \n",
    "# calculating the top 10 highest correlated features\n",
    "# with respect to the target variable i.e. \"quality\"\n",
    "plt.title(\"Top 10 highly correlated features\", size=20, pad=26)\n",
    "plt.xlabel(\"Correlation coefficient\")\n",
    "plt.ylabel(\"Features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Không làm thay đổi về correlation giữa Feature và target!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='4.3'>4.3 Fill null values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Xử lí missing data\n",
    "Có thể nhận thấy số lượng missing value khá ít, nên ta có thể fill các giá trị này bằng 1 số cách như sau:\n",
    "- Fill với mean: fill các giá trị null với giá trị mean của phân bố, đối với các skewed feature, sử dụng mean để fill các giá trị null có thể làm sai phân bố dữ liệu\n",
    "- Fill với median: fill các giá trị null với giá trị median của phân bố, sử dụng giá trị median này không làm thay đổi phân bố dữ liệu \n",
    "- Fill với giá trị có frequency nhiều nhất trong cột đó\n",
    "- Fill với 1 giá trị cố định: 0 hoặc 1.\n",
    "\n",
    "Trong trường hợp missing value quá nhiều thì sẽ không thể fill ngay, sẽ làm sai phân bố của dữ liệu từ đó làm sai việc thuật toán, tốt nhất nên trace xem lí do missing và có thể fill bằng cách nào? Khi việc fill giá trị missing trở nên risky thì nên drop luôn cột đó đi :) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Hàm xử lí missing value\n",
    "class DataFrameImputer(TransformerMixin):\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Impute missing values:\n",
    "        - Columns of dtype object are imputed with the most frequent value in column.\n",
    "        - Columns of other types are imputed with mean of column.\n",
    "        \"\"\"\n",
    "    def fit(self, X, y=None):\n",
    "\n",
    "        self.fill = pd.Series([X[c].value_counts().index[0]\n",
    "            if X[c].dtype == np.dtype('O') else X[c].median() for c in X],\n",
    "            index=X.columns)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        return X.fillna(self.fill)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Việc scaler chúng ta sẽ sử dụng StandardScaler có sẵn trong sklearn cho việc rescale lại các giá trị trong dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "cols = Balanced_df.columns\n",
    "cols = list(cols.drop(['type','quality']))\n",
    "y=Balanced_df[\"quality\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(Balanced_df.loc[:, cols], y, test_size=0.33, random_state=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='5'> 5. Modeling and evaluating for regression:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hồi quy tuyến tính"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Khi sử dụng hồi quy tuyến tính, mục tiêu của chúng ta là để làm sao một đường thẳng có thể tạo được sự phân bố gần nhất với hầu hết các điểm. Do đó làm giảm khoảng cách (sai số) của các điểm dữ liệu cho đến đường đó.\n",
    "- Trong không gian hai chiều, một hàm số được gọi là tuyến tính nếu đồ thị của nó có dạng một đường thẳng. Trong không gian ba chiều, một hàm số được goi là tuyến tính nếu đồ thị của nó có dạng một mặt phẳng. Trong không gian nhiều hơn 3 chiều, khái niệm mặt phẳng không còn phù hợp nữa, thay vào đó, một khái niệm khác ra đời được gọi là siêu mặt phẳng (hyperplane)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = Pipeline([\n",
    "        ('imputer', DataFrameImputer()),\n",
    "        ('scl', StandardScaler()),\n",
    "        ('lr',  LinearRegression())\n",
    " ])  \n",
    "\n",
    "LR.fit(X_train,y_train)\n",
    "y_pred = LR.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = LR.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train rmse: \" + str(mean_squared_error(y_train, x)**0.5))\n",
    "print(\"Test rmse: \" + str(mean_squared_error(y_test, y_pred)**0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- so với scale 0-10, thì RMSE ở đây không lớn\n",
    "- Rmse bộ test nhỏ hơn bộ train => có thể không bị overfit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='5.1'> 5.1 Ordinal Classification với 10 classes sử dụng K nearest neightbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Giới thiệu về KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN (K-Nearest Neighbors) là một thuật toán đơn giản nhất trong nhóm thuật toán Học có giám sát.  Ý tưởng của thuật toán này đó là tìm output của một dữ liệu mới dựa trên output của K điểm gần nhất xung quanh nó. KNN được ứng dụng nhiều trong khai phá dữ liệu và học máy. Trong thực tế, việc đo khoảng cách giữa các điểm dữ liệu, chúng ta có thể sử dụng rất nhiều độ đo, tiêu biểu như là  manhattan, euclide, cosine,…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(url='./imgs/knn.png', width=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ví dụ như hình trên, để gán nhãn cho điểm dữ liệu hình sao, ta xét K = 3 điểm gần nhất xung quanh nó. Nhận thấy trong 3 điểm đó, có 2 điểm thuộc class B và 1 điểm thuộc class A. Như vậy ta sẽ gán nhãn cho điểm hình sao sẽ thuộc về class B\n",
    "\n",
    "Thuật toán của KNN có thể được mô tả như sau:\n",
    "\n",
    "Thuật toán:\n",
    "- Xác định tham số K số làng giềng gần nhất\n",
    "- Tính khoảng cách của đối tượng cần phân lớp tới tất cả các đối tượng có trong tập train\n",
    "- Lấy top K cho giá trị nhỏ nhất (hoặc lớn nhất)\n",
    "- Trong top K giá trị vừa lấy, ta thống kê số lượng của mỗi lớp, chọn phân lớp cho số lượng lớn nhất"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vậy K bằng bao nhiêu thì tốt ? ta sẽ cần phải thực nghiệm nhiều lần, và chọn K sao cho kết quả output là tốt nhất"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "KNN = Pipeline([\n",
    "        ('imputer', DataFrameImputer()),\n",
    "        ('scl', StandardScaler()),\n",
    "        ('clf',  KNeighborsClassifier())\n",
    " ])  \n",
    "\n",
    "KNN.fit(X_train,y_train)\n",
    "y_pred = KNN.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ~> classification với 10 classes cho ra điểm khá thấp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For weights = 'uniform'\n",
    "for n_neighbors in [5,10,15,20]:\n",
    "    KNN = Pipeline([\n",
    "        ('imputer', DataFrameImputer()),\n",
    "        ('scl', StandardScaler()),\n",
    "        ('clf',  KNeighborsClassifier(n_neighbors=n_neighbors))\n",
    "     ])  \n",
    "    KNN.fit(X_train, y_train) \n",
    "    scr = KNN.score(X_test, y_test)\n",
    "    print(\"For n_neighbors = \", n_neighbors  ,\" score is \",scr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For weights = 'distance'\n",
    "for n_neighbors in [5,10,15,20]:\n",
    "    KNN = Pipeline([\n",
    "        ('imputer', DataFrameImputer()),\n",
    "        ('scl', StandardScaler()),\n",
    "        ('clf',  KNeighborsClassifier(n_neighbors=n_neighbors, weights='distance'))\n",
    "     ])  \n",
    "    KNN.fit(X_train, y_train) \n",
    "    scr = KNN.score(X_test, y_test)\n",
    "    print(\"For n_neighbors = \", n_neighbors  ,\" score is \",scr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='5.2'> 5.2 Classification với 3 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Balanced_df['quality_label'] = Balanced_df.quality.apply(lambda q: 'bad' if q <= 5 else 'good' if q <= 7 else 'excellent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = Balanced_df.columns\n",
    "cols = list(cols.drop(['type', 'quality_label','quality']))\n",
    "y=Balanced_df[\"quality_label\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(Balanced_df.loc[:, cols], y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "KNN = Pipeline([\n",
    "        ('imputer', DataFrameImputer()),\n",
    "        ('scl', StandardScaler()),\n",
    "        ('clf',  KNeighborsClassifier())\n",
    " ])  \n",
    "\n",
    "KNN.fit(X_train,y_train)\n",
    "y_pred = KNN.predict(X_test)\n",
    "\n",
    "labels = np.unique(y_test)\n",
    "print(classification_report(y_test,y_pred))\n",
    "\n",
    "cf_matrix_df =  confusion_matrix(y_test, y_pred, labels=labels)\n",
    "\n",
    "pd.DataFrame(cf_matrix_df, index=labels, columns=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}